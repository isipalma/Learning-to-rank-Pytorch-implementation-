{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from sklearn import metrics\n",
    "\n",
    "import pickle\n",
    "import numpy\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "import Classes\n",
    "from torch import optim, nn\n",
    "from sklearn import utils\n",
    "from Functions import *\n",
    "from torch.autograd import Variable\n",
    "from torch import cat, from_numpy\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") # to do remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running training in the train setting\n"
     ]
    }
   ],
   "source": [
    "# ZEROUT_DUMMY_WORD = False\n",
    "ZEROUT_DUMMY_WORD = True\n",
    "\n",
    "## Load data\n",
    "# mode = 'TRAIN-ALL'\n",
    "mode = 'train'\n",
    "#if len(sys.argv) > 1:\n",
    "#    mode = sys.argv[1]\n",
    "#    if not mode in ['TRAIN', 'TRAIN-ALL']:\n",
    "#        print(\"ERROR! The two possible training settings are: ['TRAIN', 'TRAIN-ALL']\")\n",
    "#        sys.exit(1)\n",
    "\n",
    "print(\"Running training in the {} setting\".format(mode))\n",
    "\n",
    "data_dir = mode\n",
    "\n",
    "if mode in ['TRAIN-ALL']:\n",
    "    q_train = numpy.load(os.path.join(data_dir, 'train-all.questions.npy'))\n",
    "    a_train = numpy.load(os.path.join(data_dir, 'train-all.answers.npy'))\n",
    "    q_overlap_train = numpy.load(os.path.join(data_dir, 'train-all.q_overlap_indices.npy'))\n",
    "    a_overlap_train = numpy.load(os.path.join(data_dir, 'train-all.a_overlap_indices.npy'))\n",
    "    y_train = numpy.load(os.path.join(data_dir, 'train-all.labels.npy'))\n",
    "else:\n",
    "    q_train = numpy.load(os.path.join(data_dir, 'train.questions.npy'))\n",
    "    a_train = numpy.load(os.path.join(data_dir, 'train.answers.npy'))\n",
    "    q_overlap_train = numpy.load(os.path.join(data_dir, 'train.q_overlap_indices.npy'))\n",
    "    a_overlap_train = numpy.load(os.path.join(data_dir, 'train.a_overlap_indices.npy'))\n",
    "    y_train = numpy.load(os.path.join(data_dir, 'train.labels.npy'))\n",
    "\n",
    "q_dev = numpy.load(os.path.join(data_dir, 'dev.questions.npy'))\n",
    "a_dev = numpy.load(os.path.join(data_dir, 'dev.answers.npy'))\n",
    "q_overlap_dev = numpy.load(os.path.join(data_dir, 'dev.q_overlap_indices.npy'))\n",
    "a_overlap_dev = numpy.load(os.path.join(data_dir, 'dev.a_overlap_indices.npy'))\n",
    "y_dev = numpy.load(os.path.join(data_dir, 'dev.labels.npy'))\n",
    "qids_dev = numpy.load(os.path.join(data_dir, 'dev.qids.npy'))\n",
    "\n",
    "q_test = numpy.load(os.path.join(data_dir, 'test.questions.npy'))\n",
    "a_test = numpy.load(os.path.join(data_dir, 'test.answers.npy'))\n",
    "q_overlap_test = numpy.load(os.path.join(data_dir, 'test.q_overlap_indices.npy'))\n",
    "a_overlap_test = numpy.load(os.path.join(data_dir, 'test.a_overlap_indices.npy'))\n",
    "y_test = numpy.load(os.path.join(data_dir, 'test.labels.npy'))\n",
    "qids_test = numpy.load(os.path.join(data_dir, 'test.qids.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train (array([0, 1], dtype=int32), array([4370,  348]))\n",
      "y_dev (array([0, 1], dtype=int32), array([926, 222]))\n",
      "y_test (array([0, 1], dtype=int32), array([1233,  284]))\n",
      "q_train (4718, 33)\n",
      "q_dev (1148, 33)\n",
      "q_test (1517, 33)\n",
      "a_train (4718, 40)\n",
      "a_dev (1148, 40)\n",
      "a_test (1517, 40)\n"
     ]
    }
   ],
   "source": [
    "print('y_train', numpy.unique(y_train, return_counts=True))\n",
    "print('y_dev', numpy.unique(y_dev, return_counts=True))\n",
    "print('y_test', numpy.unique(y_test, return_counts=True))\n",
    "\n",
    "print('q_train', q_train.shape)\n",
    "print('q_dev', q_dev.shape)\n",
    "print('q_test', q_test.shape)\n",
    "\n",
    "print('a_train', a_train.shape)\n",
    "print('a_dev', a_dev.shape)\n",
    "print('a_test', a_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy_rng = numpy.random.RandomState(123)\n",
    "q_max_sent_size = q_train.shape[1]\n",
    "a_max_sent_size = a_train.shape[1]\n",
    "ndim = 5\n",
    "dummy_word_id = numpy.max(a_overlap_train)\n",
    "#print(\"Gaussian\")\n",
    "vocab_emb_overlap = numpy_rng.randn(dummy_word_id+1, ndim) * 0.25\n",
    "vocab_emb_overlap[-1] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word embedding matrix size: (17023, 50)\n"
     ]
    }
   ],
   "source": [
    "fname = os.path.join(data_dir, 'emb_aquaint+wiki.txt.gz.ndim=50.bin.npy')\n",
    "vocab_emb = numpy.load(fname)\n",
    "ndim = vocab_emb.shape[1]\n",
    "dummpy_word_idx = numpy.max(a_train)\n",
    "print(\"Word embedding matrix size:\", vocab_emb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_outs = 2\n",
    "n_epochs = 25\n",
    "#n_epochs = 5\n",
    "batch_size = 50\n",
    "learning_rate = 0.1\n",
    "max_norm = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_size 18\n",
      "n_epochs 25\n",
      "learning_rate 0.1\n",
      "max_norm 0\n"
     ]
    }
   ],
   "source": [
    "print('batch_size', batch_size)\n",
    "print('n_epochs', n_epochs)\n",
    "print('learning_rate', learning_rate)\n",
    "print('max_norm', max_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "3\n",
      "5\n",
      "(18, 1, 41, 50)\n"
     ]
    }
   ],
   "source": [
    "## 1st conv layer.\n",
    "# ndim = vocab_emb.shape[1] + vocab_emb_overlap.shape[1]\n",
    "ndim = vocab_emb.shape[1]\n",
    "\n",
    "print(vocab_emb.shape[1])\n",
    "print(vocab_emb_overlap.shape[0])\n",
    "print(vocab_emb_overlap.shape[1])\n",
    "dropout_rate = 0.5\n",
    "nkernels = 100\n",
    "q_k_max = 1\n",
    "a_k_max = 1\n",
    "\n",
    "# filter_widths = [3,4,5]\n",
    "q_filter_widths = [5]\n",
    "a_filter_widths = [5]\n",
    "\n",
    "num_input_channels = 1\n",
    "input_shape = (batch_size, num_input_channels, q_max_sent_size + 2 * (max(q_filter_widths) - 1), ndim)\n",
    "print(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model1 = Classes.SiameseNetwork()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model1.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch: 1 \tTook:2.87\n",
      "Train epoch: 2 \tTook:2.55\n",
      "Train epoch: 3 \tTook:2.39\n",
      "Train epoch: 4 \tTook:2.38\n",
      "Train epoch: 5 \tTook:2.36\n",
      "Train epoch: 6 \tTook:2.36\n",
      "Train epoch: 7 \tTook:2.49\n",
      "Train epoch: 8 \tTook:2.38\n",
      "Train epoch: 9 \tTook:2.35\n",
      "Train epoch: 10 \tTook:2.36\n",
      "No ha habido mejora\n"
     ]
    }
   ],
   "source": [
    "#Train\n",
    "train_loss = []\n",
    "lookup = Classes.LookUpWord(vocab_emb)\n",
    "\n",
    "#preparamos el dev set\n",
    "dev_q_test = lookup.out_matrix(q_dev)\n",
    "dev_a_test = lookup.out_matrix(a_dev)\n",
    "best_dev = 0\n",
    "best = False\n",
    "\n",
    "for epoch in range(1, n_epochs+1):\n",
    "\n",
    "    start_epoch = time.time()\n",
    "\n",
    "    q_train, a_train, y_train = utils.shuffle(q_train, a_train, y_train)\n",
    "    batch_id = 0\n",
    "    for x_trainq, x_traina, y_train1 in zip(batch_gen(q_train, 50), batch_gen(a_train, 50), batch_gen(y_train, 50)):\n",
    "        #model.h_t, model.c_t = repackage_hidden((model.h_t, model.c_t))\n",
    "        model1.zero_grad() # reinicia el batch, para que no se quede con los gradientes del batch anterior\n",
    "        batch_id += 1\n",
    "        x_query =lookup.out_matrix(x_trainq)  # puede ser mas eficiente esto?\n",
    "\n",
    "        x_answer = lookup.out_matrix(x_traina)\n",
    "          #inputsq, inputsa, labels = Variable(x_query), Variable(x_answer), Variable(label)\n",
    "\n",
    "        labels = Variable(from_numpy(numpy.array(y_train1)))\n",
    "        output = model1(x_query, x_answer)\n",
    "        batch_size= output.size(0)\n",
    "        output = output.view(batch_size,2)\n",
    "\n",
    "        labels = labels.long()\n",
    "        loss = criterion(output, labels)\n",
    "        train_loss.append(loss.data[0])\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "          # del x_query?\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    end_epoch = time.time()\n",
    "    took2 = end_epoch - start_epoch\n",
    "    print('Train epoch: {} \\tTook:{:.2f}'.format(epoch, took2))\n",
    "\n",
    "    dev_pred = model1(dev_q_test, dev_a_test)\n",
    "    normal_sc = score(dev_pred, y_dev)\n",
    "    map_sc = map_score(qids_dev, dev_pred, y_dev)\n",
    "    if map_sc > best_dev:\n",
    "        best_dev = map_sc\n",
    "        best = True\n",
    "\n",
    "    if epoch % 5 == 0:\n",
    "        # revisamos el mejor puntaje usando dev\n",
    "        if not best:\n",
    "            print(\"No ha habido mejora\")\n",
    "            break\n",
    "        else:\n",
    "            best = False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " when   did   amtrak   begin   operations   ?                            \n",
      " amtrak   could   face   liquidation   if   it   fails   to   meet   the   deadline   .                             \n",
      " that   's   because   ms   .   palmer   is   a   witch   ,   the   high   priestess   of   a   group   that   practices   wicca   at   fort   hood   with   the   knowledge   and   approval   of   the   u.s   .   army   .        \n",
      "1\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "#prediccion de ejemplo\n",
    "trad = Classes.Traductor()\n",
    "\n",
    "question = trad.traducir(q_test[57])\n",
    "print(\"\")\n",
    "answer = trad.traducir(a_test[40])\n",
    "wrong_answer = trad.traducir(a_test[4])\n",
    "\n",
    "print(question)\n",
    "print(answer)\n",
    "print(wrong_answer)\n",
    "print(y_test[1])\n",
    "print(y_test[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "1.00000e-04 *\n",
      "  7.4296  6.6514\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-04 *\n",
      "  8.0515  6.4145\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "47.13249835201055\n",
      "0.6030210164570313\n",
      "Variable containing:\n",
      " 2\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query_t = lookup.out_matrix(q_test)\n",
    "answer_t = lookup.out_matrix(a_test)\n",
    "\n",
    "y_pred = model1(query_t, answer_t)\n",
    "print(y_pred[1])\n",
    "print(y_pred[4])\n",
    "\n",
    "print(score(y_pred, y_test))\n",
    "print(map_score(qids_test, y_pred, y_test))\n",
    "print(y_pred.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
